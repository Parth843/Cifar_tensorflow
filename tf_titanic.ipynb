{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].dropna().median())\n",
    "    data['Embarked'] = data['Embarked'].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic_train.csv')\n",
    "\n",
    "clean_data(train)\n",
    "\n",
    "target = train['Survived'].values\n",
    "\n",
    "train.drop(['Survived'], axis = 1,inplace = True)\n",
    "\n",
    "train.set_index('PassengerId', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[features]\n",
    "\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('titanic_test.csv')\n",
    "\n",
    "clean_data(test)\n",
    "\n",
    "x_test = test[features]\n",
    "\n",
    "x_test = pd.get_dummies(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(X,target,test_size = 0.25,random_state = 1,stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "xtrain_std = sc.fit_transform(xtrain)\n",
    "xval_std = sc.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, N = xtrain_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yval = keras.utils.to_categorical(yval,2)\n",
    "ytrain = keras.utils.to_categorical(ytrain,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10,input_shape=(10,),activation='relu'))\n",
    "model.add(keras.layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8428 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8443 - val_loss: 0.4379 - val_accuracy: 0.8206\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8413 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8458 - val_loss: 0.4380 - val_accuracy: 0.8206\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8458 - val_loss: 0.4382 - val_accuracy: 0.8206\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8428 - val_loss: 0.4379 - val_accuracy: 0.8206\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8428 - val_loss: 0.4379 - val_accuracy: 0.8206\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8458 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8428 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8413 - val_loss: 0.4382 - val_accuracy: 0.8206\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8428 - val_loss: 0.4375 - val_accuracy: 0.8206\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8443 - val_loss: 0.4374 - val_accuracy: 0.8206\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8428 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8428 - val_loss: 0.4379 - val_accuracy: 0.8206\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8458 - val_loss: 0.4382 - val_accuracy: 0.8206\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8458 - val_loss: 0.4376 - val_accuracy: 0.8161\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8458 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8413 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.87 - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8428 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8428 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8428 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8413 - val_loss: 0.4377 - val_accuracy: 0.8161\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8206\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8443 - val_loss: 0.4374 - val_accuracy: 0.8206\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8428 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8458 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8413 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8428 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8443 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8428 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8413 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8161\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8443 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8443 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8206\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8473 - val_loss: 0.4375 - val_accuracy: 0.8161\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8443 - val_loss: 0.4374 - val_accuracy: 0.8206\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8428 - val_loss: 0.4371 - val_accuracy: 0.8206\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8428 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.71 - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8413 - val_loss: 0.4371 - val_accuracy: 0.8161\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8206\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8443 - val_loss: 0.4371 - val_accuracy: 0.8206\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8473 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8458 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8428 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8473 - val_loss: 0.4371 - val_accuracy: 0.8206\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8443 - val_loss: 0.4373 - val_accuracy: 0.8251\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8458 - val_loss: 0.4371 - val_accuracy: 0.8161\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8458 - val_loss: 0.4368 - val_accuracy: 0.8206\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8443 - val_loss: 0.4370 - val_accuracy: 0.8251\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8443 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8458 - val_loss: 0.4367 - val_accuracy: 0.8206\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8458 - val_loss: 0.4365 - val_accuracy: 0.8206\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8458 - val_loss: 0.4368 - val_accuracy: 0.8251\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8458 - val_loss: 0.4366 - val_accuracy: 0.8206\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8443 - val_loss: 0.4369 - val_accuracy: 0.8251\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8428 - val_loss: 0.4365 - val_accuracy: 0.8206\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8458 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8458 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8443 - val_loss: 0.4368 - val_accuracy: 0.8251\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8443 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8428 - val_loss: 0.4367 - val_accuracy: 0.8206\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8458 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8443 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8458 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8458 - val_loss: 0.4363 - val_accuracy: 0.8251\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8473 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8443 - val_loss: 0.4366 - val_accuracy: 0.8206\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8428 - val_loss: 0.4361 - val_accuracy: 0.8206\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8473 - val_loss: 0.4362 - val_accuracy: 0.8251\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8473 - val_loss: 0.4368 - val_accuracy: 0.8161\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8428 - val_loss: 0.4358 - val_accuracy: 0.8206\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8428 - val_loss: 0.4364 - val_accuracy: 0.8206\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8443 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8428 - val_loss: 0.4360 - val_accuracy: 0.8206\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8428 - val_loss: 0.4357 - val_accuracy: 0.8161\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8443 - val_loss: 0.4358 - val_accuracy: 0.8206\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8443 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8473 - val_loss: 0.4362 - val_accuracy: 0.8206\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8458 - val_loss: 0.4361 - val_accuracy: 0.8161\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8443 - val_loss: 0.4362 - val_accuracy: 0.8206\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8443 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8458 - val_loss: 0.4356 - val_accuracy: 0.8206\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8473 - val_loss: 0.4368 - val_accuracy: 0.8161\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8443 - val_loss: 0.4361 - val_accuracy: 0.8161\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8458 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8458 - val_loss: 0.4362 - val_accuracy: 0.8161\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8458 - val_loss: 0.4359 - val_accuracy: 0.8161\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8458 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8458 - val_loss: 0.4361 - val_accuracy: 0.8161\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8413 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8473 - val_loss: 0.4362 - val_accuracy: 0.8161\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8458 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8443 - val_loss: 0.4361 - val_accuracy: 0.8161\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8473 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8443 - val_loss: 0.4360 - val_accuracy: 0.8161\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8443 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8413 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8443 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8443 - val_loss: 0.4362 - val_accuracy: 0.8161\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8428 - val_loss: 0.4368 - val_accuracy: 0.8161\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8413 - val_loss: 0.4360 - val_accuracy: 0.8161\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8458 - val_loss: 0.4364 - val_accuracy: 0.8161\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8473 - val_loss: 0.4361 - val_accuracy: 0.8161\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8443 - val_loss: 0.4364 - val_accuracy: 0.8161\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8413 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8428 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8428 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8443 - val_loss: 0.4368 - val_accuracy: 0.8161\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8428 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8443 - val_loss: 0.4360 - val_accuracy: 0.8161\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8458 - val_loss: 0.4368 - val_accuracy: 0.8161\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8443 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8443 - val_loss: 0.4365 - val_accuracy: 0.8161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8443 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8443 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8398 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8413 - val_loss: 0.4364 - val_accuracy: 0.8161\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8413 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8413 - val_loss: 0.4370 - val_accuracy: 0.8161\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8398 - val_loss: 0.4372 - val_accuracy: 0.8161\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8428 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8413 - val_loss: 0.4365 - val_accuracy: 0.8161\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8413 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8443 - val_loss: 0.4373 - val_accuracy: 0.8161\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8413 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8428 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.8161\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8458 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8383 - val_loss: 0.4369 - val_accuracy: 0.8161\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8473 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8428 - val_loss: 0.4366 - val_accuracy: 0.8161\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8443 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8428 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8443 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8443 - val_loss: 0.4371 - val_accuracy: 0.8206\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8413 - val_loss: 0.4372 - val_accuracy: 0.8161\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8443 - val_loss: 0.4367 - val_accuracy: 0.8251\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8473 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8443 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8443 - val_loss: 0.4363 - val_accuracy: 0.8161\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8443 - val_loss: 0.4367 - val_accuracy: 0.8161\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8428 - val_loss: 0.4367 - val_accuracy: 0.8206\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.78 - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8428 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8428 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8458 - val_loss: 0.4373 - val_accuracy: 0.8161\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8458 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8458 - val_loss: 0.4369 - val_accuracy: 0.8206\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8443 - val_loss: 0.4371 - val_accuracy: 0.8161\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8443 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8443 - val_loss: 0.4368 - val_accuracy: 0.8206\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8443 - val_loss: 0.4370 - val_accuracy: 0.8161\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8443 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8458 - val_loss: 0.4370 - val_accuracy: 0.8251\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8458 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8473 - val_loss: 0.4373 - val_accuracy: 0.8206\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8458 - val_loss: 0.4374 - val_accuracy: 0.8251\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8458 - val_loss: 0.4371 - val_accuracy: 0.8206\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8458 - val_loss: 0.4372 - val_accuracy: 0.8206\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8428 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8428 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8443 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8443 - val_loss: 0.4370 - val_accuracy: 0.8251\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8458 - val_loss: 0.4377 - val_accuracy: 0.8206\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8503 - val_loss: 0.4370 - val_accuracy: 0.8251\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8488 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8473 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8458 - val_loss: 0.4375 - val_accuracy: 0.8251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8443 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8458 - val_loss: 0.4374 - val_accuracy: 0.8251\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8488 - val_loss: 0.4374 - val_accuracy: 0.8251\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8458 - val_loss: 0.4372 - val_accuracy: 0.8251\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8458 - val_loss: 0.4376 - val_accuracy: 0.8206\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8443 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8473 - val_loss: 0.4377 - val_accuracy: 0.8251\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8458 - val_loss: 0.4377 - val_accuracy: 0.8251\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8443 - val_loss: 0.4373 - val_accuracy: 0.8251\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8473 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8473 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8443 - val_loss: 0.4380 - val_accuracy: 0.8206\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8458 - val_loss: 0.4372 - val_accuracy: 0.8251\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8473 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8473 - val_loss: 0.4379 - val_accuracy: 0.8251\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8458 - val_loss: 0.4383 - val_accuracy: 0.8206\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8488 - val_loss: 0.4373 - val_accuracy: 0.8251\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8473 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8458 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8206\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8443 - val_loss: 0.4377 - val_accuracy: 0.8251\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8473 - val_loss: 0.4382 - val_accuracy: 0.8251\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8473 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8458 - val_loss: 0.4375 - val_accuracy: 0.8251\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8443 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.4379 - val_accuracy: 0.8251\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8458 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8458 - val_loss: 0.4379 - val_accuracy: 0.8251\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4376 - val_accuracy: 0.8251\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8473 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8458 - val_loss: 0.4381 - val_accuracy: 0.8251\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4379 - val_accuracy: 0.8251\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8488 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8458 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8443 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8473 - val_loss: 0.4382 - val_accuracy: 0.8251\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8458 - val_loss: 0.4381 - val_accuracy: 0.8251\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4382 - val_accuracy: 0.8251\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8473 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8458 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8458 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8428 - val_loss: 0.4381 - val_accuracy: 0.8251\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8473 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8458 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8458 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8458 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8488 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8458 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8458 - val_loss: 0.4379 - val_accuracy: 0.8251\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8458 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8458 - val_loss: 0.4393 - val_accuracy: 0.8251\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8488 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8488 - val_loss: 0.4374 - val_accuracy: 0.8251\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8488 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8473 - val_loss: 0.4380 - val_accuracy: 0.8251\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.93 - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8488 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8458 - val_loss: 0.4393 - val_accuracy: 0.8251\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8488 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8458 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8488 - val_loss: 0.4378 - val_accuracy: 0.8251\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8428 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8488 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8473 - val_loss: 0.4382 - val_accuracy: 0.8251\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8428 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8458 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8443 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8458 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8458 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8458 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8458 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8473 - val_loss: 0.4381 - val_accuracy: 0.8251\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8473 - val_loss: 0.4383 - val_accuracy: 0.8251\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8458 - val_loss: 0.4390 - val_accuracy: 0.8251\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8473 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8488 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8458 - val_loss: 0.4391 - val_accuracy: 0.8251\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8458 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8458 - val_loss: 0.4394 - val_accuracy: 0.8251\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8473 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8458 - val_loss: 0.4382 - val_accuracy: 0.8251\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.4390 - val_accuracy: 0.8251\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8473 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8458 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8458 - val_loss: 0.4395 - val_accuracy: 0.8251\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8473 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8458 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8428 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8488 - val_loss: 0.4387 - val_accuracy: 0.8251\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8428 - val_loss: 0.4388 - val_accuracy: 0.8251\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8443 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.4391 - val_accuracy: 0.8251\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8443 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8443 - val_loss: 0.4386 - val_accuracy: 0.8251\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8443 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8473 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8488 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.4389 - val_accuracy: 0.8251\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.4391 - val_accuracy: 0.8251\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8458 - val_loss: 0.4385 - val_accuracy: 0.8251\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8488 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8488 - val_loss: 0.4384 - val_accuracy: 0.8251\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8443 - val_loss: 0.4393 - val_accuracy: 0.8251\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(xtrain_std,ytrain,validation_data=(xval_std,yval),epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_std).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('titanic_tf5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.78468 score on kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x180ec640cc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('titanic_tf_solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
